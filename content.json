{"meta":{"title":"Endless August","subtitle":null,"description":"None","author":"TchaikovDriver","url":"https://tchaikovdriver.github.io"},"pages":[{"title":"categories","date":"2018-09-16T13:30:24.000Z","updated":"2018-09-16T14:04:09.331Z","comments":true,"path":"categories/index.html","permalink":"https://tchaikovdriver.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-09-16T13:32:36.000Z","updated":"2018-09-16T14:04:20.514Z","comments":true,"path":"tags/index.html","permalink":"https://tchaikovdriver.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"1.6 OpenGL Camera","slug":"1-6-OpenGL-Camera","date":"2018-09-16T12:32:51.000Z","updated":"2018-09-16T13:43:23.473Z","comments":true,"path":"2018/09/16/1-6-OpenGL-Camera/","link":"","permalink":"https://tchaikovdriver.github.io/2018/09/16/1-6-OpenGL-Camera/","excerpt":"","text":"1.6 OpenGL Camera[TOC] 一、前言在《1.6 OpenGL坐标系统》里，我曾经给出下集预告，说将会在下一篇文章里详细讲解Camera部分，刘老师从不食言，今天，我们就来研究一下Camera。 我们再来看一次这张图： OpenGLCoordinateSystem 在2.WORLD SPACE中，我们把Camera从$Y$轴正方向朝向$Y$轴负方向，这样取的景就是我们布置的模型世界的俯视图，这样摆放Camera就相当于给出一个View Matrix，使得顶点乘以这个矩阵后，能变换到俯视图里的位置。 所以，本文的主题就是如何设置我们的View Matrix。 二、相机Camera1. 确定相机位置与方向我们先来思考一下，在三维空间里，我们怎么确立一个相机？显然，我们首先要确定位置（position），确定位置以后，我们还要确定方向（direction），也就是视角。位置可以用坐标点来表示，而方向则可以用空间内任意一个坐标点跟位置坐标点联合表示（即向量）： $position = (x_p, y_p, z_p)$ $target = (x_t, y_t, z_t)$ 我们的方向direction就可以用向量来表示： $\\vec{direction} = target - position = (x_t - x_p, y_t - y_p, z_t - z_p)$ 这时候我们就碰到一个问题：我们怎么确定相机的正反？想象一下，我们现在拿着相机对着某处拍照，正常情况下我们是正着拿相机（顶朝上），拍摄出来的照片自然是正的；当我们把相机反过来（顶朝下），拍照出来的照片就相当于做了180度旋转一样。因此，我们还需要额外的参数来确定相机的“正反”。 除了方向向量以外，我们还需要指定相机顶部朝上和正右侧的向量来完全确定相机的“正反”。参照下图里的最后一张图，我们最终需要3个互相垂直的向量来确定相机的位置和方向： CameraVector 首先我们确定了$position = (0, 0, 2)$，随后我们的朝向原点拍摄，$target = (0, 0, 0)$，这时候我们就先确立了第一个方向向量$direction = position - target = (0, 0, 2)$，注意这里的$direction$跟拍摄方向是相反的，后边会解释原因，为了方便后边的计算，我们把$direction$向量标准化为单位向量（模为1的向量）： $direction = \\frac{direction}{||direction||} = \\frac{(0, 0, 2)}{2} = (0, 0, 1)$ 接着，我们需要确定相机的$right$向量，以表示相机的右侧，这里会用到向量叉积的特性，这里我们先简单地回顾一下向量叉积和右手定则： 右手定则 我们做叉积$\\vec{C} = \\vec{A} \\times \\vec{B}$的时候，首先要确定向量的方向，我们将大拇指以外的四根手指指向$\\vec{A}$，然后四指向$\\vec{B}$向量方向弯曲，此时，大拇指指向的方向就是向量叉积得到的新向量$\\vec{C}$的方向。更多关于向量叉积的内容请参阅《1.4 线性代数基础与矩阵变换原理》。 回到我们的Camera，我们要求相机的右方向，也就是$\\vec{right}$，而我们已经有了$\\vec{direction}$向量了，利用叉积的性质，我们定义一个$\\vec{up} = (0, 1, 0)$，也就是垂直于$X$-$Z$平面的向量，我们用这两个向量做叉积，来求$\\vec{right}$向量： $\\vec{right} = \\vec{up} \\times \\vec{direction} = (1, 0, 0)$ 可以看出，这里的$\\vec{right}$碰巧是$X轴$的正方向的单位向量，碰巧而已，不要在意。 这下我们只剩下相机的顶部朝向，也就是$\\vec{top}$向量了，聪明的各位应该能想到，我们同样用向量的叉积来求$\\vec{top}$： $\\vec{top} = \\vec{direction} \\times \\vec{right} = (0, 1, 0)$ 这下，我们就得到了能确定相机位置、方向的三个单位向量： $\\vec{diretion} = (0, 0, 1)$ $\\vec{right} = (1, 0, 0)$ $\\vec{top} = (0, 1, 0)$ 这里需要特别注意的是，$\\vec{direction}, \\vec{right}, \\vec{top}$这三个向量必须是单位向量，也就是向量的模必须为1，如果模不为1的话，需要将各个分量都除以该向量的模来得到单位向量。 2. 计算View Matrix既然知道了相机三个方向的向量，我们就可以开始着手计算View Matrix了。 在这之前，我们要了解一下两个几何概念： 标准正交基（Orthonormal Basis） 在欧几里德空间$R^3$中，向量$\\vec{v_1} = (1, 0, 0), \\vec{v_2} = (0, 1, 0), \\vec{v_3} =(0, 0, 1)$是一组标准正交基，这三个基向量的线性组合能展开整个三维欧几里德空间。可以认为，一个坐标系统可以由一组标准正交基来定义。 右手坐标系 right_hand_coordinate 接下来，我们研究一下相机调整视角的几何意义。 OpenGLCoordinateSystem 我们可以参考上图，当我们把相机在$Y$轴正方向垂直向负方向拍摄时，我们能看到世界的俯视图。这个过程实际上是把World Space里的坐标变换到View Space里，这个变换的几何意义就是把顶点坐标从以$(1, 0, 0), (0, 1, 0), (0, 0, 1)$为标准正交基的坐标系变换到以$\\vec{right}, \\vec{top}, \\vec{direction}$为标准正交基的坐标系（这也是为什么上边我们要求三个向量都必须为单位向量）。 那么，我们这个坐标系转换要怎么做呢？ 坐标系变换我们从线性代数的角度来解答这个问题。假设我们有一个父坐标空间$P$，其标准正交基为$\\vec{v_1}, \\vec{v_2}, \\vec{v_3}$，有一个子坐标空间$C$，其标准正交基为$\\vec{u_1}, \\vec{u_2}, \\vec{u_3}$。我们可以用父坐标空间的标准正交基的线性组合来表示子坐标空间的标准正交基： $\\vec{u_1} = a_{11}\\vec{v_1} + a_{12}\\vec{v_2} + a_{13}\\vec{v_3}$ $\\vec{u_2} = a_{21}\\vec{v_1} + a_{22}\\vec{v_2} + a_{23}\\vec{v_3}$ $\\vec{u_3} = a_{31}\\vec{v_1} + a_{32}\\vec{v_2} + a_{33}\\vec{v_3}$ 这个线性组合可以用矩阵来表示： $\\begin{bmatrix}\\vec{u_1} \\\\ \\vec{u_2} \\\\ \\vec{u_3}\\end{bmatrix} = M_{camera} \\cdot \\begin{bmatrix}\\vec{v_1} \\\\ \\vec{v_2} \\\\ \\vec{v_3}\\end{bmatrix} = \\begin{bmatrix}a_{11} &amp; a_{12} &amp; a_{13} \\\\ a_{21} &amp; a_{22} &amp; a_{23} \\\\ a_{31} &amp; a_{32} &amp; a_{33} \\end{bmatrix} \\cdot \\begin{bmatrix}\\vec{v_1} \\\\ \\vec{v_2} \\\\ \\vec{v_3}\\end{bmatrix}$ 通过这个矩阵$M_{camera}$，我们能把坐标基从父坐标空间变换到子坐标空间，同理，我们的顶点也可以通过跟这个矩阵相乘来实现坐标系的变换（因为每个顶点都是标准正交基的线性组合）。 现在我们知道了坐标系要怎么变换了，我们回到计算View Matrix环节。 由于我们World Space的标准正交基是$(1, 0, 0), (0, 1, 0), (0, 0, 1)$，而View Space的标准正交基是$\\vec{right}, \\vec{top}, \\vec{direction}$，所以我们的坐标系变换矩阵就是 $M_{camera} = \\begin{bmatrix}\\vec{right}_x &amp; \\vec{right}_y &amp; \\vec{right}_z \\\\ \\vec{top}_x &amp; \\vec{top}_y &amp; \\vec{top}_z \\\\ \\vec{direction}_x &amp; \\vec{direction}_y &amp; \\vec{direction}_z \\end{bmatrix}$ 转成齐次坐标可用的形式就是 $M_{camera} = \\begin{bmatrix}\\vec{right}_x &amp; \\vec{right}_y &amp; \\vec{right}_z &amp; 0 \\\\ \\vec{top}_x &amp; \\vec{top}_y &amp; \\vec{top}_z &amp; 0 \\\\ \\vec{direction}_x &amp; \\vec{direction}_y &amp; \\vec{direction}_z &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix}$ 有人可能会问，为什么是$right, top, direction$这个顺序排列？因为我们的父坐标空间跟子坐标空间都是右手坐标系，标准正交基的排列顺序跟坐标点的x, y, z分量排列顺序一致。 通过矩阵$M_{camera}$，我们可以实现顶点坐标系的切换，相当于调整了视角。但是，我们还忽略了另一个关键因素——视距。视距怎么体现？我们可以想象，在World Space中，我们有一个在$Z$正半轴上的相机，相机朝向$Z$负半轴拍摄，当我们把相机向后移动（$Z$坐标增大），我们会感觉世界“远去”；当我们把相机向前移动（$Z$坐标减少），我们会感觉世界“靠近”。没错，其实相机的位置$position(x, y, z)$相当于将World Space坐标向反方向平移。 在《1.4 线性代数基础与矩阵变换原理》里，我们曾经介绍过平移矩阵，结合$position(x, y, z)$我们可以写出平移矩阵： $M_{translation} = \\begin{bmatrix}1 &amp; 0 &amp; 0 &amp; -position_x \\\\ 0 &amp; 1 &amp; 0 &amp; -position_y \\\\ 0 &amp; 0 &amp; 1 &amp; -position_z \\\\ 0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}$ 因为$M_{camera}$和$M_{translation}$都是线性变换，我们可以通过矩阵相乘来把这坐标系变换、平移变换组合在一起，组合结果就是我们想要的View Matrix： $M_{view} = M_{camera} \\cdot M_{translation} = \\begin{bmatrix}\\vec{R}_x &amp; \\vec{R}_y &amp; \\vec{R}_z &amp; 0 \\\\ \\vec{T}_x &amp; \\vec{T}_y &amp; \\vec{T}_z &amp; 0 \\\\ \\vec{D}_x &amp; \\vec{D}_y &amp; \\vec{D}_z &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix} \\cdot \\begin{bmatrix}1 &amp; 0 &amp; 0 &amp; -P_x \\\\ 0 &amp; 1 &amp; 0 &amp; -P_y \\\\ 0 &amp; 0 &amp; 1 &amp; -P_z \\\\ 0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix} $ 其中$\\vec{R} = \\vec{right}, \\vec{T} = \\vec{top}, \\vec{D} = \\vec{direction}, \\vec{P} = \\vec{position}$ 三、OpenGL计算View Matrix前边我们已经讲了View Matrix的推导过程，那么在实际OpenGL开发中，我们是怎么获取View Matrix呢？ GLM提供了glm::lookAt(glm::vec3&amp; eye, glm::vec3&amp; center, glm::vec3&amp; up)函数供我们直接获取View Matrix，其中eye参数就是相机的$position$；center是相机的$target$，即相机注视的点，用于计算$\\vec{direction}$；up参数，用于计算$\\vec{right}$。 在上边的例子里，我们可以这样获取View Matrix： 12345glm::mat4 viewMatrix = glm::lookAt( glm::vec3(0.0f, 0.0f 2.0f), glm::vec3(0.0f, 0.0f, 0.0f), glm::vec3(0.0f, 1.0f, 0.0f)); 四、总结至此，我们的OpenGL入门系列已经走到尾声，看完OpenGL入门系列文章，相信大家对OpenGL的基础概念以及原理都会有一定程度的了解。往后就是OpenGL进阶系列，在进阶系列出来之前，大家可以去https://learnopengl.com/Getting-started/Creating-a-window 或者 https://learnopengl-cn.github.io/01%20Getting%20started/02%20Creating%20a%20window/ 加深对OpenGL的认识和了解。","categories":[{"name":"OpenGL ES","slug":"OpenGL-ES","permalink":"https://tchaikovdriver.github.io/categories/OpenGL-ES/"}],"tags":[{"name":"OpenGL ES","slug":"OpenGL-ES","permalink":"https://tchaikovdriver.github.io/tags/OpenGL-ES/"}]},{"title":"1.5 OpenGL坐标系统","slug":"1-5-OpenGL坐标系统","date":"2018-09-16T12:31:50.000Z","updated":"2018-09-16T13:42:33.292Z","comments":true,"path":"2018/09/16/1-5-OpenGL坐标系统/","link":"","permalink":"https://tchaikovdriver.github.io/2018/09/16/1-5-OpenGL坐标系统/","excerpt":"","text":"1.5 OpenGL坐标系统[TOC] 一、概述我们曾经在《1.1 基本概念介绍》里，简单地展示过OpenGL里的坐标转换过程（这张图将会在后边被多次引用）： OpenGLCoordinateSystem 在Vertex Shader运行后，我们可见的所有顶点都会转变成标准化设备坐标（Normal Device Coordinate，简称NDC），换句话说，每个顶点的x，y，z坐标都在[-1, 1]区间内，不在这个区间内的坐标都将不可见。我们一般只需要指定一个坐标范围，然后在Vertex Shader中将范围内的坐标转换为NDC，最后这些NDC坐标在OpenGL中会被传给光栅器（Rasterizer），最终变为屏幕上的二维坐标，也就是像素。 如图所示，将坐标转换为NDC，接着再转换成屏幕坐标的过程是分步进行的，类似于流水线（Pipeline）一样。将这个过程拆分成多个坐标系的转换过程有一个好，一些操作或者说变换在特定的坐标系里会更加易于进行。这些坐标系分别是： Local Space（Object Space），本地坐标空间 World Space，世界坐标空间 View Space（Eye Space），观察坐标空间 Clip Space Screen Space 在Vertex Shader中，一般顶点坐标是这样计算的： 123456789layout (location = 0) in vec3 aPos;uniform mat4 model;uniform mat4 view;uniform mat4 projection;void main() &#123; gl_Position = projection * view * model * vec4(aPos, 1.0);&#125; 可以看出，所有顶点是依次经过model，view和projection矩阵变换最后得到NDC坐标的。 今天我们就详细讲讲这些坐标系统。 二、 坐标系统1. Local Space本地坐标空间是指创建一个空间模型时所用的坐标空间。大部分情况下，我们建立一个模型的时候，会默认以（0，0，0）为原点来建模。即便是做一个大工程，需要用到非常多的模型，我们也是从头开始，在本地坐标空间里把模型逐个搭建好，再在后续的坐标空间里进行整合。 以建立立方体模型为例，顶点坐标设置如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243float vertices[] = &#123; // 一个立方体六个面，每个面由两个三角形组成，每个三角形三个点，共36个点 -0.5f, -0.5f, -0.5f, 0.5f, -0.5f, -0.5f, 0.5f, 0.5f, -0.5f, 0.5f, 0.5f, -0.5f, -0.5f, 0.5f, -0.5f, -0.5f, -0.5f, -0.5f, -0.5f, -0.5f, 0.5f, 0.5f, -0.5f, 0.5f, 0.5f, 0.5f, 0.5f, 0.5f, 0.5f, 0.5f, -0.5f, 0.5f, 0.5f, -0.5f, -0.5f, 0.5f, -0.5f, 0.5f, 0.5f, -0.5f, 0.5f, -0.5f, -0.5f, -0.5f, -0.5f, -0.5f, -0.5f, -0.5f, -0.5f, -0.5f, 0.5f, -0.5f, 0.5f, 0.5f, 0.5f, 0.5f, 0.5f, 0.5f, 0.5f, -0.5f, 0.5f, -0.5f, -0.5f, 0.5f, -0.5f, -0.5f, 0.5f, -0.5f, 0.5f, 0.5f, 0.5f, 0.5f, -0.5f, -0.5f, -0.5f, 0.5f, -0.5f, -0.5f, 0.5f, -0.5f, 0.5f, 0.5f, -0.5f, 0.5f, -0.5f, -0.5f, 0.5f, -0.5f, -0.5f, -0.5f, -0.5f, 0.5f, -0.5f, 0.5f, 0.5f, -0.5f, 0.5f, 0.5f, 0.5f, 0.5f, 0.5f, 0.5f, -0.5f, 0.5f, 0.5f, -0.5f, 0.5f, -0.5f, &#125;; 2. World Space上一小节我们提出了在Local Space中建立模型，也就是说，基本上我们所有模型都是基于（0，0，0）原点建立的，如果直接把这些模型都绘制出来的话，可能最终效果我们会看到所有这些模型都堆在一个地方重叠了，这显然不是我们想要的效果。为了将每个模型放到它应在的位置，我们引入了世界坐标空间的概念。我们为某个模型定义一个偏移量（offset），例如说在X轴上偏移2，在Y轴上偏移5，在Z轴上偏移-15，也就是把这个模型做一个（2， 5，-15）的平移操作，平移后这个模型到了它应在的位置，这时候，我们可以认为它的顶点坐标是属于世界坐标空间的。 OpenGLCoordinateSystem 让我们回顾一下这张图，刚刚说的平移操作其实就是model矩阵的变换结果，我们通过model矩阵，把某个模型的所有顶点统一地移动到了某个位置，这样我们就把模型顶点坐标从Local Space变换到World Space了。 Model变换矩阵不仅仅可以完成平移操作，还可以完成缩放、和旋转的操作。例如说我们想画多个立方体，这些立方体零散分布在空间中，这时其实就是在逐个绘制立方体时，给每个立方体一个model矩阵，每个model矩阵都有自己的平移、旋转、缩放参数，把model矩阵的值赋给Vertex Shader，这样最终绘制出来的效果就是每个立方体都在不同的位置，大小、方向各不相同，这就是世界空间坐标以及model矩阵变换的意义。 3. View Space观察坐标空间，在OpenGL中通常会理解为相机空间或者视觉空间。View Space是将World Space坐标转换成用户视角上的坐标。不妨想象一下在一个世界坐标空间内，我们放置了许多立方体，我们可以从一个屏幕上观察这些立方体，而屏幕内容就是来自一个摄像机（Camera），随着摄像机的移动，视角调整，我们可以从不同角度、不同方向观察这些立方体。 反过来看，我们移动摄像机，其实就相当于我们自身不动，移动的是整个世界坐标空间，通过矩阵变换，我们让特定的一些顶点靠近Camera，一些顶点远离Camera，这样，就实现了我们想要的调整视角、视距来观察世界的效果。 OpenGLCoordinateSystem 从图中可以看出，这些变换会存储在View Matrix中，View Matrix会将顶点坐标从World Space变换到View Space中。关于这部分我们会在下一篇文章里更加详细地展开讲解。 4. Clip Space当所有Vertex Shader运行完之后，OpenGL希望大部分坐标会落在一个特定的范围里，而不在这个范围内的坐标都会被裁剪掉（Clipped），这就是Clip Space命名缘由。裁剪多余的坐标后，剩余的坐标就会形成Fragment，也就是光栅化，最后出现在屏幕上。 跟之前的类似，我们会定义一个Projection Matrix来完成从View Space到Clip Space的坐标变换。在Projection Matrix里，我们指定了坐标的范围，例如[-1000, 1000]，接下来，我们定义的坐标范围在[-1000, 1000]内的顶点都会被按比例映射到[-1, 1]区间内；而在[-1000, 1000]区间外的顶点都会映射到[-1, 1]区间外，最终会被裁剪掉。 如果我们绘制的是一个图元（primitive），例如说一个三角形，这个三角形的顶点坐标跨度比较大，超出了我们定义的坐标范围的话，那么OpenGL会自动重新构造一个或者多个三角形（最终顶点范围都在[-1, 1]内）来适应坐标范围。 形象地说，Projection Matrix会创建一个视锥（Frustum），所有在视锥里的坐标点都会出现在屏幕上。这种将特定范围内的坐标映射到NDC坐标中的过程称为投影。当所有顶点坐标都转换到Clip Space之后，我们会把顶点坐标的x，y，z分量都除以齐次坐标的w分量，得到其原始坐标，这个过程叫作透视除法，了解一下。这一步会在Vertex Shader执行的最后阶段里自动执行。 在该阶段过后，我们的坐标就会映射为屏幕坐标（通过glViewport方法设置），并光栅化为Fragment输出。 根据表现形式的不同，投影一般分为两种，一种是正射投影（Orthographic Projection），另一种是透视投影（Perspective Projection），两种投影分别会建立不同的视锥体（Frustum），视觉效果的差别也会因为视锥体的不同而差异化。 4.1 正射投影 Orthographic Projection正射投影定义了一个长方体样式的视锥体，不在该视锥体范围内的顶点都会被裁剪掉（如图）。 Orthographic Projection Frustum 当创建正射投影矩阵时，我们需要指定视锥体的长、宽、高，具体来说就是X轴的坐标范围、Y轴的坐标范围以及近平面、远平面的距离。我们可以使用GLM的函数来获取正射投影矩阵： 1glm::mat4 projection = glm::ortho(0.0f, 800.0f, 0.0f, 600.0f, 0.1f, 100.0f); 这样我们就定义了视锥体left为0，right为800，bottom为0，top为600，近平面距离0.1，远平面距离100f的长方体。 正射投影的思想非常直观，但是会造成不真实的视觉效果，因为它没有将透视效果考虑进去。正射投影跟透视投影的区别可以通过下图来辨别： Differences between orthographic projection and perspective projection 4.2 透视投影 Perspective Projection透视投影其实已经在前边的文章里讲过了，这里简单复习一下。在现实生活中，我们知道远处的东西看起来更小，而近处的东西看起来更大；两条无限延伸、互相平行的直线会在地平线处汇聚在一起。这种奇妙的效果我们称之为透视。 透视投影矩阵会定义一个四棱锥柱样式的视锥体，除此之外还会修改每个顶点的w分量，距离Camera越远的顶点坐标的w分量就越大，被变换到Clip Space的坐标都会落到[-w, w]区间内，不在该区间内的顶点都会被裁剪掉。而因为OpenGL要求最终坐标需要在[-1, 1]区间内，所以所有坐标的所有分量都会除以w分量（透视除法），得到最终在[-1, 1]区间内的坐标。当w分量越大的时候，做透视除法后的坐标值就越小，这样物体在视觉上就越小，这也就是我们需要的“透视”效果。 我们可以通过GLM的内置函数建立透视投影矩阵： 1glm::mat4 projection = glm::perspective(glm::radians(45.0f), (float)width/(float)height, 0.1f, 100.0f); 这里我们指定了fov（Field of View，视角大小）为45度（转为弧度），宽高比，近平面距离0.1f，远平面距离100f的一个视锥体： Perspective Projection Frustum 近平面距离一般设置为0.1f，远平面距离一般设置为100f。 至于如何根据这些参数来计算透视投影矩阵，请参阅《1.4 线代基础与矩阵变换原理》。 5. Screen Space在进行透视除法后，我们得到了NDC坐标，剩下的就交给OpenGL自行把NDC坐标转换成屏幕像素坐标，也就是把NDC坐标映射到Screen Space当中。在进行最后一步之前，我们需要通过glViewport(x, y, width, height)来告诉OpenGL我们展示用的窗口大小是多少，绘制时的横纵轴偏移值x，y分别是多少。 最终坐标的形式如下： $\\begin{bmatrix}x_w \\\\ y_w \\\\ z_w\\end{bmatrix} = \\begin{bmatrix}\\frac{width}{2}x_{ndc} + x + \\frac{width}{2} \\\\ \\frac{height}{2}y_{ndc} + y + \\frac{height}{2} \\\\ \\frac{far - near}{2}z_{ndc} + \\frac{far + near}{2}\\end{bmatrix}$ 可以通过结果推导出Viewport Matrix： $\\begin{bmatrix}\\frac{width}{2} &amp; 0 &amp; 0 &amp; x + \\frac{width}{2} \\\\ 0 &amp; \\frac{height}{2} &amp; 0 &amp; y + \\frac{height}{2} \\\\ 0 &amp; 0 &amp; \\frac{far - near}{2} &amp; \\frac{far + near}{2} \\\\ 0 &amp; 0&amp; 0&amp; 1 \\end{bmatrix}$ 大家可以画图比划一下。 三、总结我们来结合下图总结一下OpenGL中坐标的变换过程。 OpenGLPipeline 首先，我们在Local Space里建立好模型，得到一系列model coordinates顶点，通过将这些顶点坐标左乘Model Matrix，我们对模型进行了平移、旋转和缩放，得到了world coordinates顶点；接下来，我们调整Camera，观察我们所需要的视角，这一步通过讲顶点坐标左乘View Matrix完成，得到eye coordinates顶点；然后，我们根据实际需要对模型进行投影变换（正射投影或者透视投影），讲顶点坐标左乘Projection Matrix得到clip coordinates，紧接着我们对齐次坐标形式的顶点的x, y, z, w分量都除以w分量，也就是做透视除法，得到NDC坐标；最后，我们通过glViewport(x, y, width, height);方法告诉OpenGL绘制窗口的大小，让OpenGL自行将NDC坐标转换成屏幕坐标，最后在屏幕上渲染出我们想要的图像。上述local coordinates到clip coordinates的过程可以用这么一条式子表达：$V_{clip} = M_{projection} \\cdot M_{view} \\cdot M_{model} \\cdot V_{local}$ 需要注意的是在OpenGL里，向量跟矩阵相乘是从右往左计算的，所以这里的计算过程实际上是$M_{model}$先与$V_{local}$相乘，计算结果再跟$M_{view}$相乘，最后再跟$M_{projection}$相乘。 至此，OpenGL从原始顶点数据到最终在屏幕上渲染出来的流水线过程讲诉完毕。","categories":[{"name":"OpenGL ES","slug":"OpenGL-ES","permalink":"https://tchaikovdriver.github.io/categories/OpenGL-ES/"}],"tags":[{"name":"OpenGL ES","slug":"OpenGL-ES","permalink":"https://tchaikovdriver.github.io/tags/OpenGL-ES/"}]},{"title":"1.4 OpenGL线性代数基础与矩阵变换原理","slug":"1-4-OpenGL线性代数基础与矩阵变换原理","date":"2018-09-16T12:30:45.000Z","updated":"2018-09-16T13:42:44.421Z","comments":true,"path":"2018/09/16/1-4-OpenGL线性代数基础与矩阵变换原理/","link":"","permalink":"https://tchaikovdriver.github.io/2018/09/16/1-4-OpenGL线性代数基础与矩阵变换原理/","excerpt":"","text":"1.4 线代基础与矩阵变换原理[TOC] 一、前言撰写本文的主要目的是讲述计算机图形学中，向量和点通过矩阵运算来实现平移、缩放、旋转以及透视投影的原理。虽然文章主标题是”OpenGL入门”，但是从范畴上来说，这些原理并不局限于OpenGL，因为这些都是计算机图形学的内容，无论是在OpenGL，DirectX还是Vulkan，这些原理都是通用的。本文首先会讲一些前提背景知识，如一些线性代数的基础，接下来会依次讲解平移、缩放、旋转和透视投影的原理，这些原理都是基于前面说到的线性代数的基础，而且这些基础不难理解，大家看的时候毋须有畏难心理。对于线性代数零基础的同学来说，如果碰到看不懂的地方，可以反复看第一小节的线性代数基础，同时可以作图辅助理解，再有问题也可以来找刘老师一起探讨。 二、数学基础1. 向量1.1什么是向量？在计算机图形学中，向量（Vector）是最基本的运算元素之一。 向量是指具有大小（长度）和方向的量，印刷体一般用粗体表示，而手写体一般在向量名上方加箭头表示。如图所示，向量$\\vec{BA}$的计算方法就是用A点坐标减去B点坐标，向量$\\vec{BA}$的方向用箭头标出，长度（向量的模）为向量的所有分量的平方和的平方根。 OpenGL_vector 因为向量只是表示方向和大小的量，因此，向量保持方向不变，在空间内任意平移，平移后的向量都与平移前的向量相等。像上图画的一样，对向量$\\vec{BA}$的点B平移到坐标原点得到向量$\\vec{OA’}$，$\\vec{OA’}$ = $\\vec{BA}$。 1.2 向量运算由于时间关系，大家可以认为向量没有除法这回事，所以我们这里会简单地说下向量的加法和乘法。 向量的乘法有两种，一种是点积（也叫点乘），另一种是叉积（也叫叉乘）。点积的计算结果是标量，而叉积的计算结果是矢量（也就是向量）。 如图，点积的计算实际上就是讲两个向量的每个分量分别相乘并求和，也可以通过计算两个向量的模的积再乘以两个向量夹角的余弦值得出。点积的几何意义在于可以计算两个向量之间的夹角。点积满足乘法的交换、分配和结合律。 OpenGL_vector_dot_mul 在3D图像空间中，向量叉积会用到单位向量（i, j, k），其计算方法如下： OpenGL_vector_x_mul 在3D图像空间中，叉积的几何意义很有用，我们可以通过计算向量$\\vec{a}$和$\\vec{b}$的叉积得到垂直于向量$\\vec{a}$和$\\vec{b}$的向量$\\vec{c}$，$\\vec{c}$的模是$\\vec{a}$和$\\vec{b}$的模的乘积再乘以两个向量之间夹角的正弦值。光看图里的计算结果可能不太清楚计算方式，如果找不到规律的话，请找刘老师详谈。 1.3 右手定则在物理学中，我们曾经用过“右手定则”：在磁场中，有一根通电导线，将手张开，拇指垂直于其余四根手指，让磁感线垂直于掌心所在的平面，拇指以外的四根手指指向导线电流方向，这样大拇指指向的方向就是导线的运动方向。 上面给出的例子只是“右手定则”在物理学中的一个应用场景，“右手定则”其实是用来判断向量叉积的方向的。 定义矢量$\\vec{A}$×矢量$\\vec{B}$的结果为一矢量$\\vec{C}$，其大小为|$\\vec{A}$||$\\vec{B}$|sinθ，θ为$\\vec{A}$与$\\vec{B}$的夹角。其方向满足右手定则：伸直右手四指指向$\\vec{A}$的方向，沿着小于π的角度将四指卷向$\\vec{B}$的方向，则拇指的指向即为叉积$\\vec{C}$的方向。 右手定则 撸牙签示意图 2. 矩阵2.1 何为矩阵？矩阵，顾名思义，就是矩形的数列，在计算机图形学中，矩阵一般用于给向量做线性变换，不然矩阵也不会出现在我写的这篇文章里是吧。 2.2 矩阵运算我就不造轮子了，有关矩阵的运算（加、减、数乘、乘法、转置）可以看这里。 3. 齐次坐标在“矩阵”小节里，我们知道了点坐标可以写为$[x, y, z]$，那我们怎么去区分点和向量？这时候我们就引入了“齐次坐标”的概念，齐次坐标就是将一个原本是n维的向量用一个n+1维的向量来表示，是指一个用于投影几何里的坐标系统。 《计算机图形学（OpenGL版）》的作者F.S. Hill Jr.曾经说过：“齐次坐标表示是计算机图形学的重要手段之一，它既能够用来明确区分向量和点，同时也更易用于进行仿射（线性）几何变换。” 那么，齐次坐标是如何区分点和向量的呢？非常简单，齐次坐标引入了w分量，若三维空间里的一个点坐标是[x, y, z]的话，那么其齐次坐标就表示为$[x, y, z, 1]$或者$[wx, wy, wz, w] (w \\neq 0)$；如果一个向量是$[x, y, z]$的话，那么该向量的齐次坐标表示形式则是$[x, y, z, 0]$。我们随时可以通过截掉最后的$w$分量来获取原本的点/向量，而且我们还可以通过$w$分量来区分点和向量，这是齐次坐标的其中一个好处，另一个好处（更易于进行线性几何变换），会在下边提及。 4.三角函数这个大家肯定都不陌生，给大家复习一下： $cos(α + β) = cosαcosβ - sinαsinβ \\\\ cos(α - β) = cosαcosβ + sinαsinβ \\\\ sin(α + β) = sinαcosβ + cosαsinβ \\\\ sin(α - β) = sinαcosβ - cosαsinβ$ 三、线性变换什么是线性变换线性变换的定义可以看这里 假设线性空间V上的一个变换$A$为线性变换，对于V中的任意元素$\\vec{a}$，$\\vec{b}$和数域$P$中的任意$k$，都有 $A(\\vec{a}+\\vec{b}) = A(\\vec{a}) + A(\\vec{b}) \\\\ A(k\\vec{a}) = kA(\\vec{a})$ 1.平移1.1 推导我们知道，在欧几里德空间（也就是我们常用的直角坐标系、三维空间坐标系等）里，向量的平移可以通过向量加法来实现。像下图的$\\vec{OA’}$平移到$\\vec{AB}$仅需加一个向量$\\vec{OA}$就可以了。 VectorAddition 我们不难看出，向量的平移可以用如下式子表示： $\\begin{bmatrix}x \\\\ y \\\\ z\\end{bmatrix} + \\begin{bmatrix}T_x \\\\ T_y \\\\ T_z\\end{bmatrix} = \\begin{bmatrix}x + T_x \\\\ y + T_y \\\\ z + T_z\\end{bmatrix}$ 其中$T_x$，$T_y$，$T_z$分别是向量在$X$，$Y$，$Z$轴上的平移量。 在线性代数中，一个变换通常是用矩阵x向量的形式来表达，而且GPU对于矩阵乘法的计算非常高效，所以我们总是希望对向量/坐标的变换能用矩阵乘法来实现。 假设存在一个矩阵$A$，$A$乘以一个三维顶点的坐标： $A\\begin{bmatrix}x \\\\ y \\\\ z\\end{bmatrix} = \\begin{bmatrix}a_{11} &amp;&amp; a_{12} &amp;&amp; a_{13} \\\\ a_{21} &amp;&amp; a_{22} &amp;&amp; a_{23} \\\\ a_{31} &amp;&amp; a_{32} &amp;&amp; a_{33} \\end{bmatrix} \\begin{bmatrix}x \\\\ y \\\\ z\\end{bmatrix} = \\begin{bmatrix}a_{11}x &amp;&amp; a_{12}y &amp;&amp; a_{13}z \\\\ a_{21}x &amp;&amp; a_{22}y &amp;&amp; a_{23}z \\\\ a_{31}x &amp;&amp; a_{32}y &amp;&amp; a_{33}z \\end{bmatrix} $ 可以看出，无论矩阵$A$里的各个元素取什么值，我们都只能得到$x$，$y$，$z$的线性组合，无法得到一个$x$，$y$，$z$加上一个常数的结果。这时候，齐次坐标的优良特性就凸显出来了。 首先我们先把向量$[x, y, z]$转成齐次坐标的形式$[x, y, z, 1]$，对于这样的坐标，我们很简单就能拼出符合我们预期的矩阵： $A\\begin{bmatrix}x \\\\ y \\\\ z\\end{bmatrix} = \\begin{bmatrix}1 &amp; 0 &amp; 0 &amp; T_x \\\\ 0 &amp; 1 &amp; 0 &amp; T_y \\\\ 0 &amp; 0 &amp; 1 &amp; T_z \\\\ 0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix} \\begin{bmatrix}x \\\\ y \\\\ z \\\\ 1\\end{bmatrix} = \\begin{bmatrix}x + T_x \\\\ y + T_y \\\\ z + T_z \\\\ 1\\end{bmatrix}$ 这样，矩阵$A$就是我们所需要的能实现平移顶点的变换矩阵。 1.2 OpenGL ES计算平移矩阵在OpenGL ES中，计算平移矩阵的方法很简单，几句代码就搞定： 12345// 初始化矩阵float[] matrix = new float[16];Matrix.setIdentityM(m, 0);// 计算平移矩阵Matrix.translateM(m: matrix, offset: 0, x: 3f, y: 2f, z: 1f); 这样我们就能得到一个能把顶点在X轴上平移3，在Y轴上平移2，在Z轴上平移1的变换矩阵。 我们不妨看一下里边的实现： 123456public static void translateM(float[] m, int mOffset, float x, float y, float z) &#123; for (int i=0 ; i&lt;4 ; i++) &#123; int mi = mOffset + i; m[12 + mi] += m[mi] * x + m[4 + mi] * y + m[8 + mi] * z; &#125;&#125; 按实现代码来写矩阵的话，我们会得到$\\begin{bmatrix}1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ T_x &amp; T_y &amp; T_z &amp; 1\\end{bmatrix}$，为什么这跟我们推导的矩阵不一样？其实在OpenGL里，矩阵元素排序采用的是以列为主的顺序（column major order），我们不难发现，其实这个矩阵跟我们上面推导的矩阵是互为转置的关系，假设我们推导的矩阵为M，OpenGL的矩阵为A，那么$M = A^T$。 2.缩放2.1 推导如图，向量$\\vec{OP}$在x和y方向上都放大了1.5倍就得到了向量 $\\vec{OP_1}$，坐标从(2,1)变换成了(3, 1.5)。这种缩放方式比较符合我们常识中的「放大」或「缩小」，即各个维度上都「放大」或「缩小」相同的倍数。如果在3D空间中的一个对象的各个顶点都「放大」或「缩小」相同的倍数，那么这个3D对象本身就「放大」或「缩小」了相应的倍数。 向量缩放 但是，OpenGL ES里的缩放变换可以表达更一般的情形，也就是各个维度上缩放不同的倍数。还是以上图2维向量为例，向量$\\vec{OP}$在$x$方向上缩小为原来的0.5倍，在$y$方向上放大为原来的2倍，就得到了向量 $\\vec{OP_2}$，坐标从(2, 1)变换成了(1, 2)，这也是一种缩放变换。 从上面的例子可见，缩放变换就是把各个维度的坐标分别「放大」或「缩小」一个倍数。扩展到3D空间，仍然使用4维的齐次坐标，缩放操作用矩阵乘法可以写成： $\\begin{bmatrix}S_x &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; S_y &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; S_z &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix} \\begin{bmatrix}x \\\\ y \\\\ z \\\\ 1\\end{bmatrix} = \\begin{bmatrix}S_xx\\\\ S_yy \\\\ S_zz\\\\ 1\\end{bmatrix}$ 缩放比较简单，没啥好说的。 2.2 OpenGL ES计算缩放矩阵计算缩放矩阵同样灰常简单，初始化矩阵的代码就不放出来了 1Matrix.scaleM(m: matrix, offset: 0, x: 1f, y: 1.5f, z: 2f); 这样我们就能得到一个能把顶点y坐标放大1.5倍，z坐标放大2倍的缩放矩阵了。我们再来看里边的实现： 12345678public static void scaleM(float[] m, int mOffset, float x, float y, float z) &#123; for (int i=0 ; i&lt;4 ; i++) &#123; int mi = mOffset + i; m[ mi] *= x; m[ 4 + mi] *= y; m[ 8 + mi] *= z; &#125;&#125; 同样这里的矩阵也是跟我们的推导矩阵是互为转置的关系，但是因为缩放矩阵只在对角线上有元素，所以这个矩阵转置前和转置后是一样的。 3.旋转3.1 围绕坐标轴旋转旋转是相对平移和缩放来说，比较复杂的一种线性变换。在OpenGL ES中，计算旋转矩阵一般是通过一下语句实现： Matrix.rotateM(matrix: mMVPMatrix, offset: 0, angle: 30f, x: 0f, y: 0f, z: 1f); 上面的语句就是计算围绕向量$[0, 0, 1]$旋转30度的变换矩阵，也就是围绕$Z$轴旋转30度。 PointRotation 从上面的示意图我们可以看出，点$P(x, y, z)$围绕$Z$轴旋转θ度得到点$P’(x’, y’, z)$，$z$坐标没有任何变化，我们可以把点$P$和点$P’$投影到$X$-$Y$平面上，得到点$Q$和点$Q’$，$\\vec{OQ}$和$\\vec{OQ’}$的夹角也等于$θ$。这样，我们就把问题简化成平面几何了： PointRotationXYConduct 我们通过简单的几何知识可以计算出旋转后的P’坐标与P坐标的关系，计算结果显示，x’和y’都是x和y的线性组合，因此我们可以通过矩阵来表示这个变换： $M \\cdot \\begin{bmatrix}x \\\\ y \\\\ z \\\\ 1\\end{bmatrix} = \\begin{bmatrix}xcosθ + ysinθ \\\\ -xsinθ + ycosθ \\\\ z \\\\ 1\\end{bmatrix} $ $M = \\begin{bmatrix}cosθ &amp; sinθ &amp; 0 &amp; 0 \\\\ -sinθ &amp; cosθ &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}$ 矩阵$M$就是我们需要的，将三维空间内任意一个顶点$P$围绕$Z$轴旋转$θ$度得到新顶点$P’$的变换矩阵。 同理，我们不难得出围绕其他坐标轴旋转的变换矩阵： $M = \\begin{bmatrix}cosθ &amp; 0 &amp; sinθ &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ -sinθ &amp; 0 &amp; cosθ &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}$ 围绕$Y$轴旋转 $M = \\begin{bmatrix}1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; cosθ &amp; sinθ &amp; 0 \\\\ 0 &amp; -sinθ &amp; cosθ &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}$ 围绕$X$轴旋转 3.2 围绕任意向量旋转上面我们讲了如何求围绕坐标轴旋转的变换矩阵，但是这种旋转方式属于特殊案例，在实际开发中，我们更多地会围绕某个非坐标轴的向量旋转，这里的计算就比上面的特殊情况复杂得多。 先放结论，在三维空间中任意一顶点/向量$P$围绕任意一个向量$V$旋转$θ$度得到新顶点/向量$P’$的变换矩阵如下： $M = \\begin{bmatrix}x^2(1-cosθ) + cosθ &amp; xy(1-cosθ)-zsinθ &amp; xz(1-cosθ) + ysinθ &amp; 0 \\\\ xy(1-cosθ) + zsinθ &amp; y^2(1-cosθ) + cosθ &amp; yz(1-cosθ)-xsinθ &amp; 0 \\\\ zx(1-cosθ)-ysinθ &amp; yz(1-cosθ)+xsinθ &amp; z^2(1-cosθ)+cosθ &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}$ 我们不难看出，得到这个变换矩阵的过程会比较繁琐，但是没关系，刘老师会尽可能把推导过程讲诉清楚。 假设我们要对三维空间里的向量$\\vec{v}$围绕某个单位向量（向量的模为1）$\\vec{r}$旋转$θ$度，可以给出这样的图像： VectorRotationPic1 首先，我们把向量$\\vec{v}$分解为向量$\\vec{v_{||}}$的和向量$\\vec{v_⊥}$的和： $\\vec{v} = \\vec{v_{||}} + \\vec{v_⊥}$ _式1_ 其中$\\vec{v_{||}}$是与$\\vec{r}$平行的向量，$\\vec{v_⊥}$是与$\\vec{r}$互相垂直的向量。利用向量点积的几何意义，我们可以得出$\\vec{v_{||}}$的表达式： $\\vec{v_{||}} = (\\vec{v} \\cdot \\vec{r}) \\cdot \\vec{r}$ _式2_ 根据_式1_，$\\vec{v_⊥}$可以表现为如下形式： $\\vec{v_⊥} = \\vec{v} - \\vec{v_{||}} $ $ = \\vec{v} - (\\vec{v} \\cdot \\vec{r}) \\cdot \\vec{r}$ _式3_ 旋转变换为T $T(\\vec{v}) = T( \\vec{v_{||}} + \\vec{v_⊥})$ $= T( \\vec{v_{||}}) + T(\\vec{v_⊥})$ $= \\vec{v_{||}} + T(\\vec{v_⊥})$ _式4_ 计算变换矩阵的重点就在于计算$T(\\vec{v_⊥})$。 我们焦点放到$\\vec{v_⊥}$所在的平面上 VectorRotationGeneral2 我们作一个辅助向量 $\\vec{w} = \\vec{r} × \\vec{v_{⊥}}$ $= \\vec{r} × \\vec{v}$ 这里先证明下为什么$\\vec{r} × \\vec{v_{⊥}} = \\vec{r} × \\vec{v}$ 首先根据右手定则，$\\vec{r} × \\vec{v_{⊥}}$和$\\vec{r} × \\vec{v}$计算出的向量方向必然一致，接下来我们再证明两个向量的模一样即可。 $|\\vec{r} × \\vec{v_{⊥}}| = |\\vec{r}| \\cdot |\\vec{v_{⊥}}| \\cdot sin90$ $ = |\\vec{v_{⊥}}| \\cdot sin90$ 因为$\\vec{r}$是单位向量，模为1 $= |\\vec{v_{⊥}}|$ sin90 = 1 $|\\vec{r} × \\vec{v}| = |\\vec{r}| \\cdot |\\vec{v}| \\cdot sin\\psi$ VectorRotationPic1 可以看出，$|\\vec{v}| \\cdot sin\\psi = |\\vec{v_{⊥}}|$ 所以$|\\vec{r} × \\vec{v}| = |\\vec{r}| \\cdot |\\vec{v}| \\cdot sin\\psi = |{\\vec{v_{⊥}}}|$ 因此 $\\vec{w} = \\vec{r} × \\vec{v_{⊥}} = \\vec{r} × \\vec{v}$ _式5_ 回到$\\vec{v_{⊥}}$所在平面的向量分解示意图： VectorRotationGeneral2 我们可以得出 $T(\\vec{v_{⊥}}) = cosθ\\vec{v_{⊥}} + sinθ\\vec{w}$ $= cosθ\\vec{v_{⊥}} + sinθ(\\vec{r} × \\vec{v})$ _式6_ 联立_式2_，_式3_，_式4_，_式5_，_式6_，我们可以展开$T(\\vec{v})$： $T(\\vec{v}) = \\vec{v_{||}} + T(\\vec{v_{⊥}})$ $= (\\vec{v} \\cdot \\vec{r}) \\cdot \\vec{r} + cosθ\\vec{v_{⊥}} + sinθ(\\vec{r} × \\vec{v})$ $= (\\vec{v} \\cdot \\vec{r}) \\cdot \\vec{r} + cosθ[\\vec{v} - (\\vec{v} \\cdot \\vec{r}) \\cdot \\vec{r}]+ sinθ(\\vec{r} × \\vec{v})$ $= (\\vec{v} \\cdot \\vec{r}) \\cdot \\vec{r} + cosθ\\vec{v} - cosθ(\\vec{v} \\cdot \\vec{r}) \\cdot \\vec{r}+ sinθ(\\vec{r} × \\vec{v})$ $= (1 - cosθ)(\\vec{v} \\cdot \\vec{r}) \\cdot \\vec{r} + cosθ\\vec{v} + sinθ(\\vec{r} × \\vec{v})$ _式7_ 看起来好像有点复杂，要求$T(\\vec{v})$的话，我们就需要先求出$(\\vec{r} × \\vec{v})$和$(\\vec{v} \\cdot \\vec{r}) \\cdot \\vec{r}$。 我们要求解$(\\vec{r} × \\vec{v})$，不妨先证明一下叉积的矩阵乘法表现形式： 设$\\vec{a} = (x_1, y_1, z_1), \\vec{b} = (x_2, y_2, z_2)$ 单位向量 $\\vec{i} = (1, 0, 0,) \\\\ \\vec{j} = (0,1,0) \\\\ \\vec{k} = (0, 0, 1)$ $\\vec{a}×\\vec{b} = \\begin{array} {|c c c|} i &amp; j &amp; k \\\\ x_1 &amp; y_1 &amp; z_1 \\\\ x_2 &amp; y_2 &amp; z_2 \\end{array} = \\begin{bmatrix} y_1z_2 - y_2z_1 \\\\ -(x_1z_2 - x_2z_1) \\\\ x_1y_2 - x_2yz \\end{bmatrix} = \\begin{bmatrix} y_1z_2 - y_2z_1 \\\\ x_2z_1 - x_1z_2 \\\\ x_1y_2 - x_2yz \\end{bmatrix} $ 将上述表达式写成左乘矩阵的形式： $M \\cdot \\vec{b} = M \\cdot \\begin{bmatrix}x_2 \\\\ y_2 \\\\ z_2\\end{bmatrix} = \\begin{bmatrix} y_1z_2 - y_2z_1 \\\\ x_2z_1 - x_1z_2 \\\\ x_1y_2 = x_2yz \\end{bmatrix} $ $M = \\begin{bmatrix}0 &amp; -z_1 &amp; y_1 \\\\ z_1 &amp; 0 &amp; -x_1 \\\\ -y_1 &amp; x_1 &amp; 0\\end{bmatrix}$ 假设$\\vec{r} = (x, y, z)$，那么我们有 $\\vec{r}×\\vec{v} = \\begin{bmatrix}0 &amp; -z &amp; y \\\\ z &amp; 0 &amp; -x \\\\ -y &amp; x &amp; 0\\end{bmatrix} \\cdot \\vec{v}$ 再来看$(\\vec{v} \\cdot \\vec{r}) \\cdot \\vec{r}$，同样，我们尝试把$(\\vec{v} \\cdot \\vec{r}) \\cdot \\vec{r}$表现为$M \\cdot \\vec{v}$的形式： 假设$\\vec{a} = (x_1, y_1, z_1), \\vec{b} = (x_2, y_2, z_2)$ $(\\vec{a} \\cdot \\vec{b}) \\cdot \\vec{a} = M \\cdot {\\vec{b}}$，求$M$ $\\vec{a} \\cdot \\vec{b} = x_1x_2 + y_1y_2 + z_1z_2$ $(\\vec{a} \\cdot \\vec{b}) \\cdot \\vec{a} = (x_1x_2 + y_1y_2 + z_1z_2) \\cdot \\vec{a} \\ = (x_1x_2 + y_1y_2 + z_1z_2) \\cdot \\begin{bmatrix}x_1 \\\\ y_1 \\\\ z_1\\end{bmatrix} \\\\ = \\begin{bmatrix}x_1^2x_2 + x_1y_1y_2 + x_1z_1z_2 \\\\ x_1x_2y_1 + y_1^2y_2 + y_1z_1z_2 \\\\ x_1x_2z_1 + y_1y_2z_1 + z_1^2z_2\\end{bmatrix} \\\\ = M \\cdot \\begin{bmatrix}x_2 \\\\ y_2 \\\\ z_2\\end{bmatrix} $ $M = \\begin{bmatrix} x_1^2 &amp; x_1y_1 &amp; x_1z_1 \\\\ x_1y_1 &amp; y_1^2 &amp; y_1z_1 \\\\ x_1z_1 &amp; y_1z_1 &amp; z_1^2 \\end{bmatrix}$ 套到$(\\vec{r} \\cdot \\vec{v}) \\cdot \\vec{r}$上，就是 $(\\vec{v} \\cdot \\vec{r}) \\cdot \\vec{r} = (\\vec{r} \\cdot \\vec{v}) \\vec{r} \\\\ = \\begin{bmatrix}x^2 &amp; xy &amp; xz \\\\ xy&amp; y^2 &amp; yz \\\\ xz &amp; yz &amp; z^2\\end{bmatrix} \\cdot \\vec{v}$ 将这些结果代入_式7_，我们可以得出 $T(\\vec{v}) = (1 - cosθ)\\begin{bmatrix}x^2 &amp; xy &amp; xz \\\\ xy &amp; y^2 &amp; yz \\\\ xz &amp; yz &amp; z^2\\end{bmatrix} \\vec{v} + cosθ\\vec{v} + \\begin{bmatrix}0 &amp; -z &amp; y \\\\ z &amp; 0 &amp; -x \\\\ -y &amp; x &amp; 0\\end{bmatrix}sinθ\\vec{v}$ 这里已经很接近我们的最终答案了，但是有点小问题，我们怎么把中间的cosθ融合到矩阵中？这时候就要用到单位矩阵，单位矩阵的性质非常简单粗暴，就是任何左乘单位矩阵的向量，结果都等于向量本身。也就是说，假设单位矩阵为$I$，向量为$\\vec{v}$，我们有$I \\cdot \\vec{v} = \\vec{v}$。 我们借助单位矩阵把式子变换一下： $T(\\vec{v}) = (1 - cosθ)\\begin{bmatrix}x^2 &amp; xy &amp; xz \\\\ xy &amp; y^2 &amp; yz \\\\ xz &amp; yz &amp; z^2\\end{bmatrix} \\vec{v} + cosθ\\vec{v} + \\begin{bmatrix}0 &amp; -z &amp; y \\\\ z &amp; 0 &amp; -x \\\\ -y &amp; x &amp; 0\\end{bmatrix}sinθ\\vec{v} \\\\ = (1 - cosθ)\\begin{bmatrix}x^2 &amp; xy &amp; xz \\\\ xy &amp; y^2 &amp; yz \\\\ xz &amp; yz &amp; z^2\\end{bmatrix} \\vec{v} + \\begin{bmatrix}1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1\\end{bmatrix}cosθ\\vec{v} + \\begin{bmatrix}0 &amp; -z &amp; y \\\\ z &amp; 0 &amp; -x \\\\ -y &amp; x &amp; 0\\end{bmatrix}sinθ\\vec{v} \\\\ = \\begin{bmatrix}x^2(1-cosθ) + cosθ &amp; xy(1-cosθ)-zsinθ &amp; xz(1-cosθ) + ysinθ \\\\ xy(1-cosθ) + zsinθ &amp; y^2(1-cosθ) + cosθ &amp; yz(1-cosθ)-xsinθ\\\\ zx(1-cosθ)-ysinθ &amp; yz(1-cosθ)+xsinθ &amp; z^2(1-cosθ)+cos\\end{bmatrix} \\vec{v}$ 我们成功地把$T(\\vec{v})$转换为$T(\\vec{v}) = M \\cdot \\vec{v}$的形式。由于我们用的是齐次坐标，所以最后要把矩阵$M$升一维，也就是我们一开始看到的结论： $M = \\begin{bmatrix}x^2(1-cosθ) + cosθ &amp; xy(1-cosθ)-zsinθ &amp; xz(1-cosθ) + ysinθ &amp; 0 \\\\ xy(1-cosθ) + zsinθ &amp; y^2(1-cosθ) + cosθ &amp; yz(1-cosθ)-xsinθ &amp; 0 \\\\ zx(1-cosθ)-ysinθ &amp; yz(1-cosθ)+xsinθ &amp; z^2(1-cosθ)+cosθ &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix}$ 3.3 OpenGL ES计算旋转矩阵1234// 围绕z轴旋转30度Matrix.setRotateM(m: matrix, offset: 0, angle: 30f, x: 0f, y: 0f, z: 1f);// 围绕向量(1, 3, 5)旋转45度Matrix.setRotateM(m: matrix, offset: 0, angle: 45f, x: 1f, y: 3f, z: 5f); 实现比较长，这里就不贴出来了，算出来的矩阵同样跟我们推导的矩阵是互为转置关系。 四、透视投影因为透视投影是一种非线性变换，所以单独开一个章节来写。 1. 什么是透视投影透视投影是渲染管线(Rendering Pipeline)的重要组成部分，是将相机空间(Camera Space)中的点从视锥体(Frustum)变换到规则观察体(Canonical View Volume)中，待裁剪完毕后进行透视除法的行为。 从几何层面来说，透视投影就是把欧几里德空间里的点映射到一个新的空间的手段。 2. 为什么要透视投影为什么我们需要透视投影？我们可以反过来想这个问题：为什么不用欧几里德三维空间？欧几里德三维空间里每个点都可以找到它们的坐标，而且非常直观，小孩子都能直接利用坐标来作图，为什么不用呢？ 原因很简单，欧几里德是一个“理想化”的空间，在这个空间里，平行的线是永远不会相交的，这违背了人类视觉的观感（见下图）。 Railway 3. 透视投影数学原理3.1 映射的概念透视投影在数学层面上，就是坐标点的映射，映射的基本思想很简单： 给定$x\\in[a, b]$，找$y\\in[c, d]$，使得$\\frac{x-a}{b-a} = \\frac{y-c}{d-c}$ 若$x\\notin[a, b]$，则$y\\notin[c, d]$。 3.2 透视投影步骤 用透视变换矩阵把顶点从视锥体中变换到Clip Space中 规则观察体CVV(Canonical View Volume)裁剪后进行透视除法（后边会解释） PerspectiveProjectionViewFrustum 3.3 求透视变换矩阵又到了令人紧张又兴奋的求解部分了，我们慢慢来，先观察X-Z平面： PerspectiveProjectionXZ 根据相似三角形的性质，我们可以得出 $\\frac{x}{x’} = \\frac{z}{z’} = \\frac{x}{-N}$ $x’ = -N \\cdot \\frac{x}{z}$ 同理，$y’ = -N \\cdot \\frac{y}{z}$ 对于任意一点$P = (x, y, z)$我们都可以找到透视投影后的点$P’ = (-N \\cdot \\frac{x}{z}, -N \\cdot \\frac{y}{z}, -N)$ 投影结果中，$z’$始终等于-N，但是在渲染管线中，后续会对Fragment有操作，如执行Z缓冲消隐算法，我们有必要z值保留下来，所以$P’ = (-N \\cdot \\frac{x}{z}, -N \\cdot \\frac{y}{z}, z)$ 为了让程序易于处理，我们如果把$P’$写成如下形式 $P’ = (-N \\cdot \\frac{x}{z}, -N \\cdot \\frac{y}{z}, -\\frac{az + b}{z})$ 我们把$P’$转成齐次坐标的形式： $P’ = (-N \\cdot \\frac{x}{z}, -N \\cdot \\frac{y}{z}, -\\frac{az + b}{z}, 1) $ 再把所有分量乘以$-z$，得到 $P’ = (Nx, Ny, az + b, z)$ 这样我们就可以用下面的矩阵来表示这种变换： $\\begin{bmatrix}N &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; N &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; a &amp; b \\\\ 0 &amp; 0 &amp; -1 &amp; 0\\end{bmatrix} \\cdot \\begin{bmatrix}x \\\\ y \\\\ z \\\\ 1\\end{bmatrix} = \\begin{bmatrix}Nx \\\\ Ny \\\\ az+b \\\\ -z\\end{bmatrix}$ 再把$\\begin{bmatrix}Nx \\\\ Ny \\\\ az+b \\\\ -z\\end{bmatrix}$所有分量都除以$-z$ 得到$\\begin{bmatrix}-N\\frac{x}{z} \\\\ -N\\frac{y}{z} \\\\ -\\frac{az+b}{z} \\\\ 1\\end{bmatrix}$ 这个过程就叫透视除法，会损失一些必要的信息，如原始的$z$值 为什么要把$z$写成$-\\frac{az+b}{z}$？有两点原因： $P’$的3个分量统一除以$-z$，易于使用齐次坐标变换普通坐标的方式，后续使用相对统一和高效。 CVV是一个x, y, z范围都是[-1, 1]的立方体，便于多边形的裁剪。我们可以选择适当的a和b使得$-\\frac{az+b}{z}$在$z = -N$时的值等于-1，在$Z = -F$时的值等于1。 联立两个式子 $-\\frac{az+b}{z} = -1$, when $z = -N$ $-\\frac{az+b}{z} = 1$, when $z = -$F 可得 $a = - \\frac{F + N}{F - N}$ $b = - \\frac{2FN}{F - N}$ 这样，我们就得到了我们的第一版透视变换矩阵: $\\begin{bmatrix}N &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; N &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; -\\frac{F+N}{F-N} &amp; -\\frac{2FN}{F-N} \\\\ 0 &amp; 0 &amp; -1 &amp; 0\\end{bmatrix}$ 用第一版投影矩阵可以在z上构建CVV，但是(x, y)都还没限制在[1-, 1]。我们知道$-N \\frac{x}{z}$的有效范围是投影屏幕的左边界值（left）和右边界值(right)，即$-N \\frac{x}{z} \\in [left, right]$；同理，$-N \\frac{y}{z} \\in [bottom, top]$。 我们想把$-N \\frac{x}{z} \\in [left, right]$和$-N \\frac{y}{z} \\in [bottom, top]$映射到[-1, 1]中，即 $\\frac{-N\\frac{x}{z}-left}{right - left} = \\frac{x - (-1)}{1 - (-1)}$ $\\frac{-N\\frac{y}{z}-bottom}{bottom - top} = \\frac{y - (-1)}{1 - (-1)}$ 整理一下求x, y的表达式 $x = \\frac{2Nx/(-z)}{right - left} - \\frac{right+left}{right-left}$ $y = \\frac{2Ny/(-z)}{top - bottom} - \\frac{top+bottom}{top-bottom}$ 代入点$P’$，可得 $P’ = \\begin{bmatrix}\\frac{2Nx/(-z)}{right-left} - \\frac{right+left}{right-left} \\\\ \\frac{2Ny/(-z)}{top-bottom} - \\frac{top+bottom}{top-bottom} \\\\ -\\frac{az+b}{z} \\\\ 1\\end{bmatrix} \\\\ = \\begin{bmatrix}\\frac{2Nx}{right-left} + \\frac{right+left}{right-left}z \\\\ \\frac{2Ny}{top-bottom} + \\frac{top+bottom}{top-bottom}z \\\\ az+b \\\\ -z\\end{bmatrix}$ 老规矩，我们尝试用$M \\cdot P = P’$的形式来求变换矩阵 $M \\cdot \\begin{bmatrix}x \\\\ y \\\\ z \\\\ 1\\end{bmatrix} = \\begin{bmatrix}\\frac{2Nx}{right-left} + \\frac{right+left}{right-left}z \\\\ \\frac{2Ny}{top-bottom} + \\frac{top+bottom}{top-bottom}z \\\\ az+b \\\\ -z\\end{bmatrix}$ 一波骚操作，我们得到 $\\begin{array}{c} M = \\begin{bmatrix}\\frac{2N}{right - left} &amp; 0 &amp; \\frac{right+left}{right-left} &amp; 0 \\\\ 0 &amp; \\frac{2N}{top-bottom} &amp; \\frac{top+bottom}{top-bottom} &amp; 0 \\\\ 0 &amp; 0 &amp; a &amp; b \\\\ 0 &amp; 0 &amp; -1 &amp; 0\\end{bmatrix} \\\\ a = -\\frac{F+N}{F-N} \\\\ b = -\\frac{2FN}{F - N} \\end{array}$ 这个矩阵$M$就是我们想要的透视变换矩阵。 最后我们收一下尾，算一下$left$, $right$, $top$和$bottom$的值。 我们可以在$X$-$Z$平面计算视锥体 PerspectiveProjectionXZFrustum 也可以在$Y$-$Z$平面计算视锥体 PerspectiveProjectionYZFrustum 一般建议用$Y$-$Z$平面来计算，因为少一个除法，计算效率会高一点。 至此，透视变换矩阵计算完毕。 4. OpenGL ES计算透视投影矩阵12// 计算透视矩阵，在y方向上的field of view角度为45度，aspect是宽高比，近平面距离0.1f，远平面距离100fMatrix.perspectiveM(m: matrix, offset: 0, fovy: 45f, aspect: width/(float) height, zNear: 0.1f, zFar: 100f); 可以看出，OpenGL ES是在y方向上计算的，我们先看实现： 123456789101112131415161718192021222324public static void perspectiveM(float[] m, int offset, float fovy, float aspect, float zNear, float zFar) &#123; float f = 1.0f / (float) Math.tan(fovy * (Math.PI / 360.0)); float rangeReciprocal = 1.0f / (zNear - zFar); m[offset + 0] = f / aspect; m[offset + 1] = 0.0f; m[offset + 2] = 0.0f; m[offset + 3] = 0.0f; m[offset + 4] = 0.0f; m[offset + 5] = f; m[offset + 6] = 0.0f; m[offset + 7] = 0.0f; m[offset + 8] = 0.0f; m[offset + 9] = 0.0f; m[offset + 10] = (zFar + zNear) * rangeReciprocal; m[offset + 11] = -1.0f; m[offset + 12] = 0.0f; m[offset + 13] = 0.0f; m[offset + 14] = 2.0f * zFar * zNear * rangeReciprocal; m[offset + 15] = 0.0f; &#125; 先按代码把矩阵写出来： $\\begin{bmatrix}\\frac{f}{aspect} &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; f &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\frac{N+F}{N-F} &amp; -1 \\\\ 0 &amp; 0 &amp; \\frac{2FN}{N-F} &amp; 0\\end{bmatrix}$ $f = 1/tan\\frac{fovy}{2} \\\\ N = zNear \\\\ F = zFar $ 我们把矩阵转置一下： $\\begin{bmatrix}\\frac{f}{aspect} &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; f &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\frac{N+F}{N-F} &amp; -1 \\\\ 0 &amp; 0 &amp; \\frac{2FN}{N-F} &amp; 0\\end{bmatrix}^T =\\begin{bmatrix}\\frac{f}{aspect} &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; f &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\frac{N+F}{N-F} &amp; \\frac{2FN}{N-F} \\\\ 0 &amp; 0 &amp; -1 &amp; 0\\end{bmatrix} $ 看起来好像跟我们推导的 $M = \\begin{bmatrix}\\frac{2N}{right - left} &amp; 0 &amp; \\frac{right+left}{right-left} &amp; 0 \\\\ 0 &amp; \\frac{2N}{top-bottom} &amp; \\frac{top+bottom}{top-bottom} &amp; 0 \\\\ 0 &amp; 0 &amp; -\\frac{N+F}{F-N} &amp; \\frac{-2FN}{F-N} \\\\ 0 &amp; 0 &amp; -1 &amp; 0\\end{bmatrix}$ 不太一样，可能这里有同学会质问刘老师：“怎么回事？”，但是没关系，刘老师稳得一匹，让刘老师来装完这最后一个B。 OpenGL给出的透视矩阵跟我们推导的矩阵只在前两行上看上去有区别，我们可以先看$\\frac{right+left}{right-left}$和$ \\frac{top+bottom}{top-bottom}$，由于视锥体是关于Z轴对称的，其实$right+left$和$top+bottom$的值都是0，这里我们就消掉了两个冗余项； 我们再来看$\\frac{2N}{top-bottom}$，同理，这个表达式可以写成$\\frac{2N}{2top} = \\frac{N}{top} = 1/tan\\frac{fovy}{2} = f$。 最后，看$\\frac{2N}{right-left} = \\frac{N}{right} = \\frac{N}{top \\cdot aspect} = \\frac{f}{aspect}$，至此，证明完毕。 五、后语此处应有掌声。","categories":[{"name":"OpenGL ES","slug":"OpenGL-ES","permalink":"https://tchaikovdriver.github.io/categories/OpenGL-ES/"}],"tags":[{"name":"OpenGL ES","slug":"OpenGL-ES","permalink":"https://tchaikovdriver.github.io/tags/OpenGL-ES/"}]},{"title":"1.3 OpenGL绘制矩形","slug":"1-3-OpenGL绘制矩形","date":"2018-09-16T12:27:58.000Z","updated":"2018-09-16T13:41:49.233Z","comments":true,"path":"2018/09/16/1-3-OpenGL绘制矩形/","link":"","permalink":"https://tchaikovdriver.github.io/2018/09/16/1-3-OpenGL绘制矩形/","excerpt":"","text":"1.3 绘制矩形[TOC] 一、前请提要在《1.2 绘制三角形》里，我们学习了如何绘制三角形，也知道了在OpenGL ES里面，可绘制的基本图元只有点、线和三角形。那么，这是否意味着我们不能画三角形以外的图形了呢？相信大家看到这里肯定会骂我傻子都知道肯定不可能只能画三角形。本文将会围绕“如何绘制矩形”来讲述绘制矩形的几种方式。 P.S: GLSurfaceView的配置请看《1.2 绘制三角形》，本文主要讲Renderer里用到的DrawProgram接口的实现。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class SimpleRenderer implements GLSurfaceView.Renderer &#123; /** * 承载绘制逻辑的Program */ private final DrawProgram mProgram; public SimpleRenderer(DrawProgram program) &#123; mProgram = program; &#125; @Override public void onSurfaceCreated(GL10 gl, EGLConfig config) &#123; // 指定了清空画布颜色时使用的颜色：黑色 GLES20.glClearColor(0f, 0f, 0f, 0f); // 创建绘制程序 mProgram.createProgram(gl, config); &#125; @Override public void onSurfaceChanged(GL10 gl, int width, int height) &#123; // 以像素为单位，指定了视口的左下角（在第一象限内，以（0，0）为原点的）位置。width，height————表示这个视口矩形的宽度和高度，根据窗口的实时变化重绘窗口 GLES20.glViewport(0, 0, width, height); mProgram.onSizeChanged(gl, width, height); &#125; @Override public void onDrawFrame(GL10 gl) &#123; // 清空颜色缓冲区，也就是用黑色来填充画布 GLES20.glClear(GLES20.GL_COLOR_BUFFER_BIT); // 执行绘制逻辑 mProgram.draw(gl); &#125;&#125;/** * OpenGL绘制程序接口 * &lt;p&gt; * Created by LiuYujie on 2018/1/16. */public interface DrawProgram &#123; /** * 创建GL程序，这两个参数其实我也不知道有啥用，以后再研究吧 * * @param gl GL * @param config EGLConfig */ void createProgram(GL10 gl, EGLConfig config); /** * Surface尺寸变化时触发 * * @param gl GL * @param width 新Surface宽度 * @param height 新Surface高度 */ void onSizeChanged(GL10 gl, int width, int height); /** * 执行绘制操作 * * @param gl GL */ void draw(GL10 gl);&#125; P.S中的P.S：本文的涉及的代码可以在[这里]https://github.com/TchaikovDriver/OpenGLDemo)获取。 二、绘制思路相信不用我说，大家用膝盖都能想到，在只能画点、线、三角形的前提下， 绘制一个矩形，只需要用两个全等直角三角形拼起来就可以了，实际上也确实如此。 那为什么要特意写一篇文章来说这一点？其实是想借着绘制矩形来介绍OpenGL里的几种Vertex组合图形的方式。 1. glDrawArrays方法在《OpenGL入门——三角形的绘制》里，我们在准备好Vertex Shader和Fragment Shader、传递Vertex的FloatBuffer给GL程序之后，我们调用了 1GLES20.glDrawArrays(GLES20.GL_TRIANGLES, 0, 3); 来绘制三角形。调用GLES20.glDrawArrays方法之后，GLSL程序会遍历所有enable的数组，按顺序构造出指定的基本图元（这里是三角形GLES20.GL_TRIANGLES）并绘制出来。 2. 简单粗暴地绘制用这种方式绘制矩形的话，我们需要6个点，每个三角形3个点，可以在DrawTriangleProgram的基础上修改VERTEX数组： 12345678910private static final float[] VERTEX = &#123; // 第一个三角形 -.5f, -.5f, 0f,// bottom left -.5f, .5f, 0f,// top left .5f, .5f, 0f,// top right // 第二个三角形 -.5f, -.5f, 0f,// bottom left .5f, .5f, 0f,// top right .5f, -.5f, 0f // bottom right &#125;; 接着是修改draw(GL10 gl)的实现： 12345@Overridepublic void draw(GL10 gl) &#123; // 绘制两个三角形 GLES20.glDrawArrays(GLES20.GL_TRIANGLES, 0, 6); // 6个点&#125; 这样，GL程序就会遍历mVertexBuffer里的6个点（示意图如下），前三个点ABC绘制为一个三角形，后三个点ADC绘制为另一个三角形，在视觉上这两个三角形合并为一个矩形，这样我们的矩形就绘制完毕了。 构成矩形的两个三角形 3. 开源节流——GL_TRIANGLE_STRIP在上一个简单粗暴的绘制方式里，崇尚节约的同学可能会想，一个矩形只需要4个点，上面这种方式其实有两个点是重复的，有没有办法可以复用中间两个点，减少VERTEX数组的长度？ 答案是肯定的，不然我就扯不了那么久了。 我们可以看GLES20.glDrawArrays(int mode, int first, int count)方法签名，第一个参数mode指代的是绘制模式，绘制三角形的模式，只要好奇心足够，我们会发现绘制三角形一共有三种模式： GLES20.GL_TRIANGLES，GLES20.GL_TRIANGLE_STRIP和GLES20.GL_TRIANGLE_FAN。 第一种模式GLES20.GL_TRIANGLES是遍历顶点数组，以3个为一组，3个点组合为一个三角形，依次绘制，假设传入的顶点数为n，则绘制的三角形数量是n/3。 第二种模式GLES20.GL_TRIANGLE_STRIP是遍历顶点数组，以相邻的3个点为组合，依次绘制，假设传入的定点数为n，则绘制的三角形数量是n-2（n &gt;= 3）。 第三种模式GLES20.GL_TRIANGLE_FAN是遍历顶点数组，以首个顶点为所有要绘制的三角形的其中一个点，剩下的顶点按顺序，以2个点为单位，每个单位分别与第一个顶点组合成一个三角形。 在这小节里，我们用GLES20.GL_TRIANGLE_STRIP来绘制矩形。 首先，我们要确定顶点顺序，这一点很关键，OpenGL绘制图形是按顶点顺序来组合图形的，错误的顶点顺序组合而成的图形可能会跟我们想要的结果有出入。 构成矩形的两个三角形 还是这张图，可以看出，在上一小节中我们重复声明的两个点是点A和点C，所以VERTEX数组应该这样修改： 123456private static final float[] VERTEX = &#123; -.5f, .5f, 0, // top left B .5f, .5f, 0, // top right C -.5f, -.5f, 0,// bottom left A .5f, -.5f, 0 // bottom right D &#125;; 根据注释内容可以看出，B，C，A三个点组成矩形上半部分，C，A，D三个点组成矩形的下半部分，最后，我们修改一下绘制代码： 12345@Overridepublic void draw(GL10 gl) &#123; // 绘制两个三角形 GLES20.glDrawArrays(GLES20.GL_TRIANGLE_STRIP, 0, 4); // 4个点&#125; 这样，我们就实现了用4个点来绘制矩形。 4. 随心所欲地画——glDrawElements在上面小节里，我们用GLES20.GL_TRIANGLE_STRIP的模式绘制了矩形，这个模式要求我们的VERTEX数组严格按照一定顺序来保存顶点坐标。设想一下，如果我们以后要绘制多个矩形，甚至是更复杂的图形，而这些图形中又有非常多共用的点，这种情况下怎么办？ 用GLES20.GL_TRIANGLES模式绘制会创建很多重复的点；用GLES20.GL_TRIANGLE_STRIP的话，视绘制的图形的复杂程度，我们未必能排列出一个恰好覆盖到所有图形的顶点顺序。 设计OpenGL的大佬们当然早就预料到这种case，并给出了解决方案，这个解决方案就是使用GLES20.glDrawElements(int mode, int count, int type, Buffer indices)方法来绘制图形。 这个方法对比GLES20.glDrawArrays(int mode, int first, int count)，可以说是换了个思路来组合顶点，后者是按线性顺序以及绘制模式来决定组合图形的顶点，而前者则是通过显式声明的顶点顺序来组合图形，接下来会用代码来详细讲解。 首先，我们还是定义好VERTEX数组： 123456private static final float[] VERTEX = &#123; -.5f, -.5f, 0,// bottom left A -.5f, .5f, 0, // top left B .5f, .5f, 0, // top right C .5f, -.5f, 0 // bottom right D&#125;; 可以看出，我们的顶点不能按GLES20.GL_TRIANGLES_STRIP的方式来绘制，因为复用的AC两点不在数组的中间。但是，我们知道，绘制这个矩形需要A，B，C和A，C，D来分别组成两个三角形。因此，我们确立了顶点的组合方式分别是第0，1，2和0，2，3个顶点，所以就有了下面的DRAW_INDEX数组： 1234private static final short[] DRAW_INDEX = &#123; 0, 1, 2, // 第一个三角形，用到左下，左上和右上三个点 0, 2, 3 // 第二个点，用到左下，右上和右下三个点&#125;; 因为GLES20.glDrawElements方法接受的index数据结构是Buffer，所以我们要创建一个ShortBuffer。 12345ShortBuffer indices = ByteBuffer.allocateDirect(DRAW_INDEX.length * SIZEOF_SHORT) .order(ByteOrder.nativeOrder()) .asShortBuffer() .put(DRAW_INDEX);indices.position(0); 最后，实现绘制方法： 12345@Overridepublic void draw(GL10 gl) &#123; // 声明index长度，数据类型为unsigned short，以及传入indexBuffer GLES20.glDrawElements(GLES20.GL_TRIANGLES, DRAW_INDEX.length, GLES20.GL_UNSIGNED_SHORT, indices);&#125; 这样，GL程序在绘制时就会按我们指定的顶点顺序，取第0，1，2个顶点画第一个三角形，取第0，2，3个顶点画第二个三角形，两个三角形组合成一个矩形。 在绘制复杂图形时，很多时候使用GLES20.glDrawElements方法可以节省不少顶点数组的空间，特别是每个顶点包含的信息越多的情况下（如顶点颜色）就更是如此。 5. 扩展——GL_TRIANGLE_FAN5.1 矩形前面我们有提到GLES20.GL_TRIANGLE_FAN绘制模式，这种模式是以首个顶点为所有要绘制的三角形的其中一个点，剩下的顶点按顺序，以2个点为单位，每个单位分别与第一个顶点组合成一个三角形。 下面会用这种方式来绘制矩形，需要注意的是，这种方式只会复用第一个顶点，而绘制一个矩形需要复用两个顶点，所以我们不可避免地需要多声明一个顶点： 1234567private static final float[] VERTEX = &#123; -.5f, -.5f, 0,// bottom left A -.5f, .5f, 0, // top left B .5f, .5f, 0, // top right C .5f, .5f, 0, // top right C .5f, -.5f, 0 // bottom right D&#125;; 从上面代码可以看出，我们多声明了一个顶点C，所以我们的顶点序列是ABCCD，在GLES20.GL_TRIANGLE_FAN模式下，会把A拿出来，剩下的点BCCD按序分为两组，第一组是BC，第二组是CD，这两组分别与顶点A组合，从而得到三角形ABC和三角形ACD，这样就能画出我们想要的矩形了。 实现绘制代码： 1GLES20.glDrawArrays(GLES20.GL_TRIANGLE_FAN, 0, VERTEX.length / 3); 5.2 拟合圆形看到这里，可能大家都厌倦了画矩形了，之前我们有提过可以用三角形来拟合复杂图形，现在刚好可以用GLES20.GL_TRIANGLE_FAN绘制模式来演示一下如何用三角形来拟合圆形。 拟合圆形 如上图所示，在一个圆里，以圆心为坐标原点建立直角坐标系，把圆形分割为若干等分的扇形，把圆心和扇形的射线与圆边的交点连接起来，就可以得到若干个扇形的内接三角形。当我们把圆形分割得足够多份的时候，我们用三角形拟合出来的图形就跟圆形越接近。 经过简单的数学证明（这里就不赘述了，要证明请找刘老师），我们可以用以下代码来生成顶点坐标： 123456789101112131415161718192021222324private static final float[] VERTEX;static &#123; List&lt;Float&gt; vertices = new ArrayList&lt;&gt;(); // 首个顶点为圆心，即坐标原点(0,0,0) vertices.add(0f); vertices.add(0f); vertices.add(0f); // 顶点坐标范围是[-1, 1] final float radius = 0.25f; // 将圆切割为40等份 final float deltaDegree = 360f / 20f; final float endDegree = deltaDegree + 360f; double radian; for (float i = 0; i &lt; endDegree; i += deltaDegree) &#123; radian = Math.toRadians(i); vertices.add((float)(radius * Math.sin(radian))); vertices.add((float)(radius * Math.cos(radian))); vertices.add(0f); &#125; VERTEX = new float[vertices.size()]; for (int i = vertices.size() - 1; i &gt;= 0; i--) &#123; VERTEX[i] = vertices.get(i); &#125; &#125; 由于视觉需要，我们会用到透视矩阵变换，这是超纲内容，会在下一期提到，现在大家暂且看看就好。 123456private static final String VERTEX_SHADER = \"attribute vec4 aPosition;\\n\" + \"uniform mat4 uMVPMatrix;\\n\" + \"void main() &#123;\\n\" + \"gl_Position = uMVPMatrix * aPosition;\\n\" + \"&#125;\"; 我们的VERTEX_SHADER新增了一个uMVPMatrix变量，而且会跟aPosition相乘后再赋值给gl_Position。这里其实就是对顶点坐标进行了一个矩阵变换。 接着我们要给矩阵赋值，使得这个变换有意义： 1234567// 获取uMVPMatrix的句柄int mMVPMatrixLoc = GLES20.glGetUniformLocation(programHandle, \"uMVPMatrix\");float[] mMVPMatrix = new float[16]; // MVPMatrix是4x4的矩阵// 给透视矩阵赋值Matrix.perspectiveM(matrix: mMVPMatrix, offset: 0, fovy: 45f, aspect: width / (float) height, zNear: 0.1f, zFar: 100f);// 因为设置透视矩阵后Z轴会倒置，要把图形平移到Z轴 -100f~-0.1f的范围内才可以看到Matrix.translateM(matrix: mMVPMatrix, offset: 0, x: 0, y: 0, z: -3f); 最后的绘制逻辑： 123456@Overridepublic void draw(GL10 gl) &#123; // 把计算好的矩阵传给Vertex Shader中的uMVPMatrix变量 GLES20.glUniformMatrix4fv(mMVPMatrixLoc, 1, false, mMVPMatrix, 0); GLES20.glDrawArrays(GLES20.GL_TRIANGLE_FAN, 0, VERTEX.length / 3);&#125; 运行结果预览： 拟合圆形预览 是不是很黄？","categories":[{"name":"OpenGL ES","slug":"OpenGL-ES","permalink":"https://tchaikovdriver.github.io/categories/OpenGL-ES/"}],"tags":[{"name":"OpenGL ES","slug":"OpenGL-ES","permalink":"https://tchaikovdriver.github.io/tags/OpenGL-ES/"}]},{"title":"1.2 OpenGL绘制三角形","slug":"1-2-OpenGL绘制三角形","date":"2018-09-16T11:46:50.000Z","updated":"2018-09-16T13:41:41.763Z","comments":true,"path":"2018/09/16/1-2-OpenGL绘制三角形/","link":"","permalink":"https://tchaikovdriver.github.io/2018/09/16/1-2-OpenGL绘制三角形/","excerpt":"","text":"1.2 绘制三角形[TOC] 一、扯淡本文会结合代码来讲述如何绘制三角形，也会尽可能地覆盖疑点，当然一些超纲内容刘老师还没学会，来日方长，日后再说。 绘制一个图形一般需要准备以下东西： 画布 画笔 绘制逻辑 二、画布在Android系统里使用OpenGL绘制，一般会用到GLSurfaceView或者TextureView，《OpenGL入门》系列如无意外都会采用GLSurfaceView作为教材。 GLSurfaceView内部维护着GL线程，GL线程启动的时候会创建EGLContext以及EGLSurface，而EGLSurface就是我们需要的画布，虽然我们在绘制的时候并不会直接操作EGLSurface，但是没有这个我们什么都画不了。 使用GLSurfaceView只需要做简单的配置，配置代码如下： ###1. GLSurfaceView配置代码 12345678910111213141516171819202122232425 private void initView() &#123; // 用OpenGL ES 2.0 mGLSurfaceView.setEGLContextClientVersion(2); // 配置RGBA和深度的size，因为用不上遮罩(mask)，所以stencilSize为0 mGLSurfaceView.setEGLConfigChooser(8, 8, 8, 8, 16, 0); // 配置画笔 mGLSurfaceView.setRenderer(new SimpleTriangleRenderer()); // 选择绘制模式为RENDERMODE_CONTINUOUSLY，表示不断刷新和绘制 // 另一个模式为RENDERMODE_WHEN_DIRTY，仅在调用mGLSurfaceView.requestRender()时才绘制 mGLSurfaceView.setRenderMode(GLSurfaceView.RENDERMODE_CONTINUOUSLY); &#125;@Overrideprotected void onStart() &#123; super.onStart(); // 恢复GL线程执行 mGLSurfaceView.onResume();&#125;@Overrideprotected void onStop() &#123; super.onStop(); // 暂停GL线程 mGLSurfaceView.onPause();&#125; 至此，GLSurfaceView的准备完毕。 三、画笔在上面的示例代码里，我们提到了“画笔”，这个画笔其实就是GLSurfaceView.Renderer接口的实现类。绘制一个简单的三角形，画笔并不需要复杂的准备，要做的仅仅时在执行绘制逻辑前把画布清空就可以了。 所以就有了世上最简单的画笔代码： 123456789101112131415161718192021222324252627282930313233public class SimpleRenderer implements GLSurfaceView.Renderer &#123; /** * 承载绘制逻辑的Program */ private final DrawProgram mProgram; public SimpleRenderer(DrawProgram program) &#123; mProgram = program; &#125; @Override public void onSurfaceCreated(GL10 gl, EGLConfig config) &#123; // 指定了清空画布颜色时使用的颜色：黑色 GLES20.glClearColor(0f, 0f, 0f, 0f); // 创建绘制程序 mProgram.createProgram(gl, config); &#125; @Override public void onSurfaceChanged(GL10 gl, int width, int height) &#123; // 以像素为单位，指定了视口的左下角（在第一象限内，以（0，0）为原点的）位置。width，height————表示这个视口矩形的宽度和高度，根据窗口的实时变化重绘窗口 GLES20.glViewport(0, 0, width, height); mProgram.onSizeChanged(gl, width, height); &#125; @Override public void onDrawFrame(GL10 gl) &#123; // 清空颜色缓冲区，也就是用黑色来填充画布 GLES20.glClear(GLES20.GL_COLOR_BUFFER_BIT); // 执行绘制逻辑 mProgram.draw(gl); &#125;&#125; 至此，世上最简画笔完成了。 四、绘制逻辑–三角形绘制一个三角形需要什么？我们知道，二维图形由点、线、面组成，所以我们首先要确定三个顶点（Vertex）。在OpenGL里，坐标系有x, y, z轴，因此我们的点一般有三个维度。 Vertex的坐标值取值范围是[-1, 1]，数据类型是float。 那就随便先写三个点吧 12345private static final float[] VERTEX = &#123; 0f, 1f, 0f, // Surface顶部正中央 -0.5f, -1f, 0f, // Surface 底部1/4宽度处 1f, -1f, 0f // Surface底部最右侧&#125;; 因为我们画的是2D三角形，所以Z坐标都为0，其实这里也可以不写Z坐标，用二维坐标即可，后面的代码做相应调整就可以了，为了教学方便，这里先用三维坐标。 定义了三个点以后，我们怎么把这三个点在OpenGL的世界里表现出来？ 1. Vertex Shader《OpenGL基本概念》里提过的，OpenGL的渲染需要Vertex Shader和Fragment Shader，顾名思义，存放顶点需要用到Vertex Shader，说到Shader我们就要用到GLSL(OpenGL Shading Language)，GLSL以C语言为基础的高阶着色语言，可以在这里简单了解下，现在大家先将就着看示例代码吧。 Vertex Shader代码： 123456// 用于存放顶点的4维向量attribute vec4 aPosition;void main() &#123; // 读取顶点 gl_Position = aPosition;&#125; GLSL程序使用一些特殊的内置变量来获取外部输入，gl_Position就是其中一个，用于存放顶点坐标信息，其数据类型为vec4，这也是为什么我们明明顶点是三维的，但是aPosition却要声明为vec4的原因。 2. Fragment Shader《OpenGL基本概念》里还提过光栅化(Rasterization)，也就是把点、线、三角形映射到屏幕上的像素点的过程，这个过程会生成Fragment，换句话说，我们要画的三角形就是一个Fragment，绘制Fragment的话就要准备Fragment Shader： 1234precision mediump float; // 告诉GPU浮点运算只需要中等精度void main() &#123; gl_FragColor = vec4(1, 0, 0, 1); // Fragment颜色 R G B A&#125; GLSL在进行光栅化着色的时候，会产生大量的浮点数运算，这些运算可能是当前设备不支持的，所以GLSL提供了3种浮点数精度，我们可以根据不同的设备来使用合适的精度。一般在Fragment Shader最开始的地方加上 precision mediump float; 便设定了默认的精度。这样所有没有显式表明精度的变量都会按照设定好的默认精度来处理。 跟gl_Position一样，gl_FragColor也是GLSL的内置变量，我们通过给该变量赋值从而实现给Fragment着色的效果。 3. 创建GLSL程序容器在准备好Vertex Shader和Fragment Shader后，我们就会想（或者说我会想）怎么使用这两个Shader？这就需要我们创建一个GLSL程序来装载两个Shader，都到这了我就不废话了，请看代码： 1234567891011121314151617181920212223public void createProgram(GL10 gl, EGLConfig config) &#123; // 创建GLSL程序对象并获取其句柄 int programHandle = GLES20.glCreateProgram(); // 加载vertex和fragment的shader int vertexShader = loadShader(GLES20.GL_VERTEX_SHADER, VERTEX_SHADER); int fragmentShader = loadShader(GLES20.GL_FRAGMENT_SHADER, FRAGMENT_SHADER); // attach vertex和fragment shader到GLSL程序中 GLES20.glAttachShader(programHandle, vertexShader); GLES20.glAttachShader(programHandle, fragmentShader); // 链接并启用GLSL程序 GLES20.glLinkProgram(programHandle); GLES20.glUseProgram(programHandle);&#125;private static int loadShader(int type, String shaderCode) &#123; // 创建Shader程序并获取其句柄 int shader = GLES20.glCreateShader(type); // 指定Shader源码并绑定 GLES20.glShaderSource(shader, shaderCode); // 编译Shader程序 GLES20.glCompileShader(shader); return shader;&#125; GLES20.glLinkProgram(programHandle);语句，直译就是“链接”GLSL程序，“链接”可以理解为讲编译后并与programHandle attach的Shaders都转换为可以直接在GPU内对应的处理器中（Vertex Processor和Fragment Processor）运行的可执行文件，完整描述可以看glLinkProgram Description。 GLES20.glUseProgram(programHandle);则是把已经attach了Shader和link成功后的GLSL程序投入使用，调用该语句后，后续对Shader对象的操作都不会影响到已经投入使用的GLSL程序了，这种时候可以手动删除两个Shader对象来释放资源。 4. 数据准备在大费周章准备好Vertex Shader，Fragment Shader和GLSL程序后，我们还欠缺关键的一步，就是把数据（三角形的三个顶点）传给Vertex Shader。 4.1 FloatBuffer由于OpenGL API限制的原因，我们定义的float数组并不能直接使用，为此，我们要用到Java nio包下的FloatBuffer。 123456789101112private static final float[] VERTEX = &#123; 0f, 1f, 0f, // Surface顶部正中央 -0.5f, -1f, 0f, // Surface 底部1/4宽度处 1f, -1f, 0f // Surface底部最右侧&#125;;// 每个float是4个bytesprivate static final int SIZEOF_FLOAT = 4;FloatBuffer vertexBuffer = ByteBuffer.allocateDirect(VERTEX.length * SIZEOF_FLOAT) .order(ByteOrder.nativeOrder()) .asFloatBuffer() .put(VERTEX); 如上面代码所示，我们创建了一个 9x4 = 36个bytes的FloatBuffer，字节排序顺序跟当前设备保持一致，内容就是我们定义的VERTEX数组。 4.2 传递数据传递数据的代码就三句，但是内容量不少： 1234567// 从GLSL程序中获取Vertex Shader里的aPosition的句柄int positionLoc = GLES20.glGetAttribLocation(programHandle, \"aPosition\");// 启用aPositionGLES20.glEnableVertexAttribArray(positionLoc);// 把mVertexBuffer中存储的VERTEX数组的值赋给Vertex Shader程序中的aPosition// 因为每个顶点都是3维的，所以size是3，stride的值一般是 顶点数x数据类型占用的byte数，float是4个bytes，所以stride = 12GLES20.glVertexAttribPointer(positionLoc, 3, GLES20.GL_FLOAT, false, 12, mVertexBuffer); 逐句分析 int positionLoc = GLES20.glGetAttribLocation(programHandle, &quot;aPosition&quot;); 在GLES20.glUseProgram(programHandle);后，我们用上述语句获取Vertex Shader中定义的attribute vec4 aPosition变量的句柄（可以理解为这个变量的native引用）。 随后我们用GLES20.glEnableVertexAttribArray(positionLoc);启用了aPositionattribute，为什么要做这一步呢？因为OpenGL出于性能考虑，在默认情况下，所有Vertex Shader的attribute变量都是关闭的，这意味着数据在Shader端是不可见的，如果不通过显式地调用GLES20.glEnableVertexAttribArray(positionLoc);的话，GLSL程序渲染时就无法获取到我们传入的顶点坐标，也就无法进行绘制操作了。 最后，我们通过GLES20.glVertexAttribPointer(positionLoc, 3, GLES20.GL_FLOAT, false, 12, vertexBuffer);把前边创建好的FloatBuffer vertexBuffer传给Vertex Shader的attribute vec4 aPosition变量。在该句中，我们声明了vertexBuffer中有每个顶点都是三维的，顶点坐标的数据类型是GLES20.GL_FLOAT，不需要标准化数据，每个顶点占用12个bytes（三维坐标，也就是三个float，每个float是4 bytes）。 至此，我们的数据也准备完毕了。 5. 绘制铺垫了那么久，总算到了我们蓄谋已久的绘制环节了，下面就是完整的绘制三角形的代码： 1GLES20.glDrawArrays(GLES20.GL_TRIANGLES, 0, 3); 调用GLES20.glDrawArrays方法之后，GLSL程序会遍历所有enable的数组，按顺序构造出指定的基本图元并绘制出来。 该方法接受3个参数，第一个是mode，表示我们要绘制的图元类型，这里传值 GLES20.GL_TRIANGLES，表示我们要画三角形。后两个参数分别是first和count， 相信这两个参数我不说大家也知道是咋回事。 五、示例代码搞了个OpenGLDemo工程，后续授课的示例代码都会放在里边。本期代码可以在该工程的TriangleDemoActivity里顺藤摸瓜地看。 Git工程地址：https://github.com/TchaikovDriver/OpenGLDemo","categories":[{"name":"OpenGL ES","slug":"OpenGL-ES","permalink":"https://tchaikovdriver.github.io/categories/OpenGL-ES/"}],"tags":[{"name":"OpenGL ES","slug":"OpenGL-ES","permalink":"https://tchaikovdriver.github.io/tags/OpenGL-ES/"}]},{"title":"1.1 OpenGL基本概念介绍","slug":"1-1-OpenGL基本概念介绍","date":"2018-09-16T11:45:01.000Z","updated":"2018-09-16T13:42:53.176Z","comments":true,"path":"2018/09/16/1-1-OpenGL基本概念介绍/","link":"","permalink":"https://tchaikovdriver.github.io/2018/09/16/1-1-OpenGL基本概念介绍/","excerpt":"","text":"1.1 基本概念介绍[TOC] 一、什么是OpenGL ES？OpenGL(Open Graphics Library) 是一套标准的用于渲染2D、3D矢量图形的跨语言、跨平台的应用程序编程接口（API）。而OpenGL ES(Open Graphics Library for Embedded Systems)，顾名思义，是为嵌入式系统（如移动设备的系统）特殊定制的API，去除了glBegin/glEnd，四边形（GL_QUADS）、多边形（GL_POLYGONS）等复杂图元等许多非绝对必要的特性。本次学习的OpenGL ES版本为2.0，是基于OpenGL 3.0裁剪定制而成的。 1. OpenGL功能概述 图形基本组成要素（What）：Point, Edge, Polygon 属性Attribute（How） Transformation - Viewing and Modeling从运行过程来看，OpenGL其实是一个有限状态机（finite state machine） 2. OpenGL函数命名规则 OpenGLFunctionNaming 3. OpenGL应用程序的运作流程 OpenGLProgramBaseStructure 一个交互式的OpenGL应用程序一般流程如下： 配置并创建一个窗口，用于OpenGL输出 初始化一些在整个应用程序运行期间所需的OpenGL状态值 处理用户事件，如键盘输入、触摸事件、鼠标移动或者改变窗口大小等 根据用户的输入，改变OpenGL状态值，在窗口中绘制图像 可以看出，OpenGL是非面向对象而是面向过程的，开发者需要维护一个状态机，根据用户的输入而改变OpenGL的状态，状态的变更会触发新图像的绘制，最终通过无限循环来实现交互效果。 二、OpenGL基本概念在OpenGL ES中，由于去掉了多边形这种复杂图元，所以只剩下点、线和三角形这三类图元。下面将围绕这三类图元讲诉OpenGL中的一些基本概念。 1. VertexVertex就是顶点的意思，一切图形都有Vertex，Vertex序列可以围成一个图形。 2. Fragment &amp; Rasterization光栅化（Rasterization）是指将点、线、三角形映射到屏幕上的像素点的过程，每个映射区域叫作Fragment，换句话说，光栅化就是生成Fragment的过程。 RasterizationAndFragment 3. Shader着色器程序（Shader）用于描述如何绘制（渲染），OpenGL包含了GLSL（OpenGL ShadingLanguage），是一门编程语言，语法与C语言类似。OpenGL渲染需要两种Shader: Vertex Shader和Fragment Shader。Shader的最终目的就是确定图形的Vertex坐标和Fragment颜色，我们想要用 OpenGL 实现任何效果，无论是静止的光影、色彩、形状，还是运动的物理效果、粒子效果，归根结底都是要根据时间和位置确定Vertex坐标和Fragment颜色。 下面是绘制一个红色三角形所需要的最简单的Vertex Shader和Fragment Shader的代码示例 1234567891011// Vertex Shaderattribute vec4 aPosition; // 存储了三角形三个点的向量void main() &#123; gl_Position = aPosition;&#125;// Fragment Shaderprecision mediump float; // 告诉GPU在浮点数计算时使用中等精度就可以了void main() &#123; gl_FragColor = vec4(1, 0, 0, 1); // R G B A, 红色三角形&#125; 4. 坐标系 OpenGLCoordinateSystem 下面这张图展示了 OpenGL 通常的处理流程中各个环节的坐标系，以及坐标系之间的转换操作： Local space：我们为每个物体建好模型的时候，它们的坐标就是 Local space 坐标； World space：当我们要绘制多个物体时，如果直接使用 Local space 的坐标（把所有物体的原点放在一起），它们可能会发生重叠，因此我们需要把它们进行合理的移动、排布，最终各自的坐标就是 World space 的坐标了； Model matrix：把 Local space 坐标转换到 World space 坐标所使用的变换矩阵，它是针对每个物体做不同的变换； View space：通常也叫 Camera space 或者 Eye space，是从观察者（也就是我们自己）所在的位置出发，所看到的空间； View matrix：把 World space 坐标转换到 View space 坐标所使用的变换矩阵，它相当于是在移动相机位置，实际上是反方向移动整个场景（所有物体）； Clip space：OpenGL 只会渲染坐标值范围在 [-1, 1] 的内容，超出这个范围的内容都会被裁剪掉，这个范围的空间就叫 Clip space，Clip space 的坐标系也叫 Normalized Device Coordinate（NDC）； Projection matrix：把 View space 坐标转换到 Clip space 坐标所使用的变换矩阵，它会指定一个可见的范围，只有这个范围内的点才会转换到 NDC 中，而这个范围被称作视锥（Frustum）；projection matrix 有三种创建方式：正投影（Orthographic projection），透视投影（Perspective projection），以及 3D 投影（3D projection）；前两种比较常用； Screen space：屏幕上的空间，glViewport 调用指定的区域； Viewport transform：这一步是 OpenGL 自动完成的，把 Clip space 坐标转换到 Screen space 坐标；","categories":[{"name":"OpenGL ES","slug":"OpenGL-ES","permalink":"https://tchaikovdriver.github.io/categories/OpenGL-ES/"}],"tags":[{"name":"OpenGL ES","slug":"OpenGL-ES","permalink":"https://tchaikovdriver.github.io/tags/OpenGL-ES/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-09-16T03:25:16.175Z","updated":"2018-09-16T03:25:16.175Z","comments":true,"path":"2018/09/16/hello-world/","link":"","permalink":"https://tchaikovdriver.github.io/2018/09/16/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}